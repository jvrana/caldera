{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shortest-Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix path and import caldera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, isfile\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def find_pkg(name: str, depth: int):\n",
    "    if depth <= 0:\n",
    "        ret = None\n",
    "    else:\n",
    "        d = ['..'] * depth\n",
    "        path_parts = d + [name, '__init__.py']\n",
    "        \n",
    "        if isfile(join(*path_parts)):\n",
    "            ret = d\n",
    "        else:\n",
    "            ret = find_pkg(name, depth-1)\n",
    "    return ret\n",
    "\n",
    "def find_and_ins_syspath(name: str, depth: int):\n",
    "    path_parts = find_pkg(name, depth)\n",
    "    if path_parts is None:\n",
    "        raise RuntimeError(\"Could not find {}. Try increasing depth.\".format(name))\n",
    "    path = join(*path_parts)\n",
    "    if path not in sys.path:\n",
    "        sys.path.insert(0, path)\n",
    "\n",
    "try:\n",
    "    import caldera\n",
    "except ImportError:\n",
    "    find_and_ins_syspath('caldera', 3)\n",
    "\n",
    "import caldera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "To generate examples, we are going to use caldera's networkx graph generator utilties and the `caldera.transforms.networkx` module to perform graph preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from caldera.testing import annotate_shortest_path\n",
    "from caldera.transforms import Compose\n",
    "from caldera.transforms.networkx import NetworkxAttachNumpyOneHot\n",
    "from caldera.transforms.networkx import NetworkxNodesToStr\n",
    "from caldera.transforms.networkx import NetworkxSetDefaultFeature\n",
    "from caldera.transforms.networkx import NetworkxToDirected\n",
    "from caldera.utils._tools import _resolve_range\n",
    "from caldera.utils.nx.generators import _uuid_chain\n",
    "from caldera.utils.nx.generators import chain_graph\n",
    "from caldera.utils.nx.generators import compose_and_connect\n",
    "from caldera.utils.nx.generators import random_graph\n",
    "%matplotlib inline\n",
    "\n",
    "def generate_shorest_path_example(n_nodes, density, path_length, compose_density = None):\n",
    "    d = _resolve_range(density)\n",
    "    l = _resolve_range(path_length)\n",
    "    if compose_density is None:\n",
    "        cd = d\n",
    "    else:\n",
    "        cd = _resolve_range(compose_density)\n",
    "    path = list(_uuid_chain(l))\n",
    "    h = chain_graph(path, nx.Graph)\n",
    "    g = random_graph(n_nodes, density=d)\n",
    "    graph = compose_and_connect(g, h, cd)\n",
    "\n",
    "    annotate_shortest_path(\n",
    "        graph,\n",
    "        True,\n",
    "        True,\n",
    "        source_key=\"source\",\n",
    "        target_key=\"target\",\n",
    "        path_key=\"shortest_path\",\n",
    "        source=path[0],\n",
    "        target=path[-1],\n",
    "    )\n",
    "\n",
    "    preprocess = Compose(\n",
    "        [\n",
    "            NetworkxSetDefaultFeature(\n",
    "                node_default={\"source\": False, \"target\": False, \"shortest_path\": False},\n",
    "                edge_default={\"shortest_path\": False},\n",
    "            ),\n",
    "            NetworkxAttachNumpyOneHot(\n",
    "                \"node\", \"source\", \"_features\", classes=[False, True]\n",
    "            ),\n",
    "            NetworkxAttachNumpyOneHot(\n",
    "                \"node\", \"target\", \"_features\", classes=[False, True]\n",
    "            ),\n",
    "            NetworkxAttachNumpyOneHot(\n",
    "                \"edge\", \"shortest_path\", \"_target\", classes=[False, True]\n",
    "            ),\n",
    "            NetworkxAttachNumpyOneHot(\n",
    "                \"node\", \"shortest_path\", \"_target\", classes=[False, True]\n",
    "            ),\n",
    "            NetworkxSetDefaultFeature(\n",
    "                node_default={\"_features\": np.array([0.0]), \"_target\": np.array([0.0])},\n",
    "                edge_default={\"_features\": np.array([0.0]), \"_target\": np.array([0.0])},\n",
    "                global_default={\n",
    "                    \"_features\": np.array([0.0]),\n",
    "                    \"_target\": np.array([0.0]),\n",
    "                },\n",
    "            ),\n",
    "            NetworkxNodesToStr(),\n",
    "            NetworkxToDirected(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return preprocess([graph])[0]\n",
    "\n",
    "\n",
    "def draw_shortest_path(g, ax=None, node_size=10, edge_width=0.5, cmap=None, pos=None):\n",
    "    if ax is None:\n",
    "        fig = plt.figure(figsize=(3, 3))\n",
    "        ax = fig.gca()\n",
    "    ax.axis('off')\n",
    "    \n",
    "    g = nx.to_undirected(g)\n",
    "    nodelist = list(g.nodes)\n",
    "\n",
    "    node_color = []\n",
    "    for n in nodelist:\n",
    "        node_color.append(g.nodes[n]['shortest_path'])\n",
    "\n",
    "    edge_list = []\n",
    "    edge_color = []\n",
    "    for n1, n2, edata in g.edges(data=True):\n",
    "        edge_list.append((n1, n2))\n",
    "        edge_color.append(edata['shortest_path'])\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('seismic')\n",
    "    if pos is None:\n",
    "        pos = nx.layout.spring_layout(g)\n",
    "    elif callable(pos):\n",
    "        pos = pos(g)\n",
    "    nx.draw_networkx_nodes(g, pos=pos, node_color=node_color, node_size=node_size, ax=ax, cmap=cmap)\n",
    "    nx.draw_networkx_edges(g, pos=pos, width=edge_width, edge_color=edge_color, ax=ax, edge_cmap=cmap)\n",
    "    return ax\n",
    "    \n",
    "\n",
    "def custom_layout(g):\n",
    "    s1 = []\n",
    "    s2 = []\n",
    "    for n, ndata in g.nodes(data='shortest_path'):\n",
    "        if ndata:\n",
    "            s1.append(n)\n",
    "        else:\n",
    "            s2.append(n)\n",
    "\n",
    "    sg1 = g.subgraph(s1)\n",
    "    sg2 = g.subgraph(s2)\n",
    "\n",
    "    p1 = nx.layout.spring_layout(sg1)\n",
    "    p2 = nx.layout.spring_layout(sg2)\n",
    "\n",
    "    pos = {}\n",
    "    for p_ in [p1, p2]:\n",
    "        for n in p_:\n",
    "            pos[n] = p_[n]\n",
    "    return pos\n",
    "        \n",
    "\n",
    "g = generate_shorest_path_example((10, 100), (0.03, 0.03), (5, 10), (0.01, 0.02))\n",
    "draw_shortest_path(g, pos=custom_layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 6, figsize=(12, 6))\n",
    "for row in axes:\n",
    "    for ax in row:\n",
    "        g = generate_shorest_path_example((100, 150), (0.01, 0.03), (5, 30), (0.005, 0.02))\n",
    "        draw_shortest_path(g, ax, node_size=1, edge_width=0.2, pos=custom_layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert `networkx.Graph` into GraphData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caldera.data import GraphData\n",
    "\n",
    "input_graph = GraphData.from_networkx(g, feature_key='_features')\n",
    "target_graph = GraphData.from_networkx(g, feature_key='_target')\n",
    "\n",
    "print(input_graph)\n",
    "print(target_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate `networkx.Graphs`, annotate the shortest path, convert features to `np.ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caldera.dataset import GraphDataset\n",
    "from caldera.data import GraphData, GraphBatch\n",
    "from caldera.data import GraphDataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "NUM_GRAPHS = 1000\n",
    "NUM_NODES = (10, 100)\n",
    "DENSITY = (0.01, 0.03)\n",
    "PATH_LEN  = (5, 10)\n",
    "COMPOSITION_DENSITY  = (0.01, 0.02)\n",
    "\n",
    "nx_graphs = []\n",
    "for _ in tqdm(range(NUM_GRAPHS)):\n",
    "    nxg = generate_shorest_path_example(NUM_NODES, DENSITY, PATH_LEN, COMPOSITION_DENSITY)\n",
    "    nx_graphs.append(nxg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check generated graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caldera.utils.functional import chain_each\n",
    "\n",
    "fig, axes = plt.subplots(3, 6, figsize=(12, 6))\n",
    "axes = chain_each()(axes)\n",
    "for ax, g in zip(axes, nx_graphs):\n",
    "    draw_shortest_path(g, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a paired data loader from input and target datalists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_datalist = [GraphData.from_networkx(g, feature_key='_features') for g in nx_graphs]\n",
    "target_datalist = [GraphData.from_networkx(g, feature_key='_target') for g in nx_graphs]\n",
    "\n",
    "loader = GraphDataLoader(input_datalist, target_datalist, batch_size=32)\n",
    "\n",
    "for _input, _target in loader:\n",
    "    print(_input)\n",
    "    print(_target)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot tensor object fingerprints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caldera.data.utils import graph_matrix\n",
    "from caldera.utils import functional\n",
    "import seaborn as sns\n",
    "\n",
    "def adj_fingerprint(data, step_size=50):\n",
    "    t = graph_matrix(data, include_edge_attr=False, fill_value=0, edge_value=1)\n",
    "    n = t.numpy().squeeze()\n",
    "    \n",
    "    _n = np.zeros_like(n[:step_size, :step_size])\n",
    "    for i in np.arange(0, n.shape[0], step=step_size):\n",
    "        n2 = n[i:i+step_size, i:i+step_size]\n",
    "        pad = step_size - n2.shape[0]\n",
    "        if pad > 0:\n",
    "            n2 = np.hstack([n2, np.zeros((n2.shape[0], pad))])\n",
    "            n2 = np.vstack([n2, np.zeros((pad, n2.shape[1]))])\n",
    "        _n += n2\n",
    "    return _n\n",
    "\n",
    "def plot_fingerprint(data):\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(3, 0.5))\n",
    "    gs = fig.add_gridspec(2, 5)\n",
    "    ax1 = fig.add_subplot(gs[0, :-1])\n",
    "    ax2 = fig.add_subplot(gs[1, :-1])\n",
    "    ax3 = fig.add_subplot(gs[:, -1:])\n",
    "    \n",
    "    sns.heatmap(data.x[:, :1].T, ax=ax1, cbar=False, xticklabels=False, yticklabels=False, cmap=\"gray\")\n",
    "    sns.heatmap(data.e[:, :1].T, ax=ax2, cbar=False, xticklabels=False, yticklabels=False, cmap=\"gray\")\n",
    "    \n",
    "    sns.heatmap(adj_fingerprint(data, step_size=10), cbar=False, xticklabels=False, yticklabels=False, cmap=\"gray\")\n",
    "    return fig\n",
    "\n",
    "def split(n, step_size):\n",
    "    for i in np.arange(0, n.shape[0], step=step_size):\n",
    "        n2 = n[i:i+step_size, i:i+step_size]\n",
    "        pad = step_size - n2.shape[0]\n",
    "        if pad > 0:\n",
    "            n2 = np.hstack([n2, np.zeros((n2.shape[0], pad))])\n",
    "            n2 = np.vstack([n2, np.zeros((pad, n2.shape[1]))])\n",
    "        yield n2\n",
    "\n",
    "for _input, _target in functional.iter_count(3)(loader):\n",
    "    fig = plot_fingerprint(_target)\n",
    "n = graph_matrix(_target).numpy().sum(axis=2)\n",
    "x = np.hstack(list(split(n, 100)))\n",
    "fig = plt.figure(figsize=(10, 2))\n",
    "ax = fig.gca()\n",
    "ax.set_title(\"Unrolled Adj Matrix\")\n",
    "sns.heatmap(x, ax=ax, cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the input and target data are batched together according to the batch size. Node attributes can be accessed via `x`, edge attributes `e` and global attributes `g`. Now data is ready to be loaded into a `caldera` network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Network\n",
    "\n",
    "We are going to build a graph network to handle the data we just created.\n",
    "\n",
    "We are going to use a flexible `encoder -> core[x] -> decoder` architecture for this problem. The architecture consists of 4 main networks, the **encoder**, **core**, **decoder**, and **output_transform** networks. The **encoder** encodes graph data inputs into arbitrary shapes. The **core** is the central graph message processing network. The **decoder** decodes encoded data. Finally, the **output_transform** transformed decoded data for final output. \n",
    "\n",
    "Setting up the network looks like the following:\n",
    "\n",
    "``` python\n",
    "class Network(torch.nn.Module):\n",
    "\n",
    "    def __init__(...):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.config = {...}\n",
    "\n",
    "        self.encoder = ...\n",
    "        self.core = ...\n",
    "        self.decoder = ...\n",
    "        self.out_transform = ...  \n",
    "\n",
    "    def forward(self, data, steps, save_all: bool = False):\n",
    "        \"\"\"The encoder -> core -> decode loop\"\"\"\n",
    "        encoded = self.encoder(data) # encode data\n",
    "        \n",
    "        outputs = []\n",
    "        for _ in range(steps):\n",
    "            latent = self.core(encoded)\n",
    "            encoded = self.decoder(latent)\n",
    "            outputs.append(self.out_transform(latent)\n",
    "        return outputs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flex Modules and Flex Dimensions\n",
    "\n",
    "Setting up this network with the correct dimensions can become tricky, so we introduce a new module, the `Flex` module, which can resolve unknown dimensions on runtime. To make a module a `Flex` module, we just call `Flex` with any `torch.nn.Module`, as in `Flex(torch.nn.Linear)` or `Flex(MyAwesomeModule)`. To initialize the module with unknown dimensions, you use the flexible dimension object `Flex.d` in places where the dimension is to be resolve on runtime, as in `Flex(torch.nn.Linear)(Flex.d(), 10)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caldera.blocks import Flex\n",
    "import torch\n",
    "\n",
    "FlexLinear = Flex(torch.nn.Linear)\n",
    "\n",
    "linear0 = torch.nn.Linear(3, 10)\n",
    "flex_linear0 = FlexLinear(Flex.d(), 10)\n",
    "print(linear0)\n",
    "print(flex_linear0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the FlexBlock indicates it is current unresolved. To resovle it, we need to provide it with a data example. You'll see the module is now resolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = torch.zeros((1, 10))\n",
    "\n",
    "flex_linear0(example)\n",
    "\n",
    "print(flex_linear0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregators\n",
    "\n",
    "Aggregators are layers that indicate how data is processed and aggregated between neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from caldera.blocks import NodeBlock, EdgeBlock, GlobalBlock\n",
    "from caldera.blocks import AggregatingNodeBlock, AggregatingEdgeBlock, AggregatingGlobalBlock\n",
    "from caldera.blocks import MultiAggregator\n",
    "from caldera.blocks import Flex\n",
    "from caldera.models import GraphCore, GraphEncoder\n",
    "from caldera.defaults import CalderaDefaults as defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_sizes=(16, 16, 1),\n",
    "        depths=(1, 1, 1),\n",
    "        dropout: float = None,\n",
    "        pass_global_to_edge: bool = True,\n",
    "        pass_global_to_node: bool = True,\n",
    "        edge_to_node_aggregators=tuple([\"add\", \"max\", \"mean\", \"min\"]),\n",
    "        edge_to_global_aggregators=tuple([\"add\", \"max\", \"mean\", \"min\"]),\n",
    "        node_to_global_aggregators=tuple([\"add\", \"max\", \"mean\", \"min\"]),\n",
    "        aggregator_activation=defaults.activation,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.config = {\n",
    "            \"latent_size\": {\n",
    "                \"node\": latent_sizes[1],\n",
    "                \"edge\": latent_sizes[0],\n",
    "                \"global\": latent_sizes[2],\n",
    "                \"core_node_block_depth\": depths[0],\n",
    "                \"core_edge_block_depth\": depths[1],\n",
    "                \"core_global_block_depth\": depths[2],\n",
    "            },\n",
    "            \"node_block_aggregator\": edge_to_node_aggregators,\n",
    "            \"global_block_to_node_aggregator\": node_to_global_aggregators,\n",
    "            \"global_block_to_edge_aggregator\": edge_to_global_aggregators,\n",
    "            \"aggregator_activation\": aggregator_activation,\n",
    "            \"pass_global_to_edge\": pass_global_to_edge,\n",
    "            \"pass_global_to_node\": pass_global_to_node,\n",
    "        }\n",
    "        self.encoder = GraphEncoder(\n",
    "            EdgeBlock(Flex(MLP)(Flex.d(), latent_sizes[0], dropout=dropout)),\n",
    "            NodeBlock(Flex(MLP)(Flex.d(), latent_sizes[1], dropout=dropout)),\n",
    "            GlobalBlock(Flex(MLP)(Flex.d(), latent_sizes[2], dropout=dropout)),\n",
    "        )\n",
    "\n",
    "        edge_layers = [self.config[\"latent_size\"][\"edge\"]] * self.config[\"latent_size\"][\n",
    "            \"core_edge_block_depth\"\n",
    "        ]\n",
    "        node_layers = [self.config[\"latent_size\"][\"node\"]] * self.config[\"latent_size\"][\n",
    "            \"core_node_block_depth\"\n",
    "        ]\n",
    "        global_layers = [self.config[\"latent_size\"][\"global\"]] * self.config[\n",
    "            \"latent_size\"\n",
    "        ][\"core_global_block_depth\"]\n",
    "\n",
    "        self.core = GraphCore(\n",
    "            AggregatingEdgeBlock(\n",
    "                torch.nn.Sequential(\n",
    "                    Flex(MLP)(Flex.d(), *edge_layers, dropout=dropout, layer_norm=True),\n",
    "                    # Flex(torch.nn.Linear)(Flex.d(), edge_layers[-1])\n",
    "                )\n",
    "            ),\n",
    "            AggregatingNodeBlock(\n",
    "                torch.nn.Sequential(\n",
    "                    Flex(MLP)(Flex.d(), *node_layers, dropout=dropout, layer_norm=True),\n",
    "                    # Flex(torch.nn.Linear)(Flex.d(), node_layers[-1])\n",
    "                ),\n",
    "                Flex(MultiAggregator)(\n",
    "                    Flex.d(),\n",
    "                    self.config[\"node_block_aggregator\"],\n",
    "                    activation=self.config[\"aggregator_activation\"],\n",
    "                ),\n",
    "            ),\n",
    "            AggregatingGlobalBlock(\n",
    "                torch.nn.Sequential(\n",
    "                    Flex(MLP)(\n",
    "                        Flex.d(), *global_layers, dropout=dropout, layer_norm=True\n",
    "                    ),\n",
    "                    # Flex(torch.nn.Linear)(Flex.d(), global_layers[-1])\n",
    "                ),\n",
    "                edge_aggregator=Flex(MultiAggregator)(\n",
    "                    Flex.d(),\n",
    "                    self.config[\"global_block_to_edge_aggregator\"],\n",
    "                    activation=self.config[\"aggregator_activation\"],\n",
    "                ),\n",
    "                node_aggregator=Flex(MultiAggregator)(\n",
    "                    Flex.d(),\n",
    "                    self.config[\"global_block_to_node_aggregator\"],\n",
    "                    activation=self.config[\"aggregator_activation\"],\n",
    "                ),\n",
    "            ),\n",
    "            pass_global_to_edge=self.config[\"pass_global_to_edge\"],\n",
    "            pass_global_to_node=self.config[\"pass_global_to_node\"],\n",
    "        )\n",
    "\n",
    "        self.decoder = GraphEncoder(\n",
    "            EdgeBlock(\n",
    "                Flex(MLP)(Flex.d(), latent_sizes[0], latent_sizes[0], dropout=dropout)\n",
    "            ),\n",
    "            NodeBlock(\n",
    "                Flex(MLP)(Flex.d(), latent_sizes[1], latent_sizes[1], dropout=dropout)\n",
    "            ),\n",
    "            GlobalBlock(Flex(MLP)(Flex.d(), latent_sizes[2])),\n",
    "        )\n",
    "\n",
    "        self.output_transform = GraphEncoder(\n",
    "            EdgeBlock(\n",
    "                torch.nn.Sequential(\n",
    "                    Flex(torch.nn.Linear)(Flex.d(), 1), torch.nn.Sigmoid()\n",
    "                )\n",
    "            ),\n",
    "            NodeBlock(\n",
    "                torch.nn.Sequential(\n",
    "                    Flex(torch.nn.Linear)(Flex.d(), 1), torch.nn.Sigmoid()\n",
    "                )\n",
    "            ),\n",
    "            GlobalBlock(Flex(torch.nn.Linear)(Flex.d(), 1)),\n",
    "        )\n",
    "\n",
    "    def forward(self, data, steps, save_all: bool = False):\n",
    "        # encoded\n",
    "        e, x, g = self.encoder(data)\n",
    "        data = GraphBatch(x, e, g, data.edges, data.node_idx, data.edge_idx)\n",
    "\n",
    "        # graph topography data\n",
    "        edges = data.edges\n",
    "        node_idx = data.node_idx\n",
    "        edge_idx = data.edge_idx\n",
    "        latent0 = data\n",
    "\n",
    "        meta = (edges, node_idx, edge_idx)\n",
    "\n",
    "        outputs = []\n",
    "        for _ in range(steps):\n",
    "            # core processing step\n",
    "            e = torch.cat([latent0.e, e], dim=1)\n",
    "            x = torch.cat([latent0.x, x], dim=1)\n",
    "            g = torch.cat([latent0.g, g], dim=1)\n",
    "            data = GraphBatch(x, e, g, *meta)\n",
    "            e, x, g = self.core(data)\n",
    "\n",
    "            # decode\n",
    "            data = GraphBatch(x, e, g, *meta)\n",
    "\n",
    "            _e, _x, _g = self.decoder(data)\n",
    "            decoded = GraphBatch(_x, _e, _g, *meta)\n",
    "\n",
    "            # transform\n",
    "            _e, _x, _g = self.output_transform(decoded)\n",
    "            gt = GraphBatch(_x, _e, _g, edges, node_idx, edge_idx)\n",
    "            if save_all:\n",
    "                outputs.append(gt)\n",
    "            else:\n",
    "                outputs = [gt]\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

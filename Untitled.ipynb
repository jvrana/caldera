{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/justin/anaconda3/envs/torch/lib/python3.7/site-packages/ipykernel_launcher.py:16: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  app.launch_new_instance()\n",
      "/home/justin/anaconda3/envs/torch/lib/python3.7/site-packages/ipykernel_launcher.py:17: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/home/justin/anaconda3/envs/torch/lib/python3.7/site-packages/ipykernel_launcher.py:46: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/home/justin/anaconda3/envs/torch/lib/python3.7/site-packages/torch/tensor.py:455: RuntimeWarning: Iterating over a tensor might cause the trace to be incorrect. Passing a tensor of different shape won't change the number of iterations executed (and might lead to errors or silently give incorrect results).\n",
      "  'incorrect results).', category=RuntimeWarning)\n",
      "/home/justin/anaconda3/envs/torch/lib/python3.7/site-packages/ipykernel_launcher.py:89: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/home/justin/anaconda3/envs/torch/lib/python3.7/site-packages/ipykernel_launcher.py:90: TracerWarning: Converting a tensor to a Python number might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/home/justin/anaconda3/envs/torch/lib/python3.7/site-packages/torch/jit/__init__.py:980: TracerWarning: Encountering a list at the output of the tracer might cause the trace to be incorrect, this is only valid if the container structure does not change based on the module's inputs. Consider using a constant container instead (e.g. for `list`, use a `tuple` instead. for `dict`, use a `NamedTuple` instead). If you absolutely need this and know the side effects, pass strict=False to trace() to allow this behavior.\n",
      "  _force_outplace)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830 µs ± 14.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "794 µs ± 20.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "from caldera.utils import scatter_coo\n",
    "import torch\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "from caldera.utils import torch_scatter_group\n",
    "\n",
    "\n",
    "k, v = torch_scatter_group(values, m._indices()[-1])\n",
    "data = dict(zip(k.tolist(), v))\n",
    "data\n",
    "\n",
    "# @torch.jit.script\n",
    "def _gather(data: Dict[int, torch.Tensor], indices: torch.Tensor):\n",
    "    arrs = []\n",
    "    for i in range(indices.shape[0]):\n",
    "        key = indices[i].item()\n",
    "        if key in data:\n",
    "            arrs.append(data[key])\n",
    "    if len(arrs):\n",
    "        return torch.cat(arrs)\n",
    "    return torch.Tensor([])\n",
    "\n",
    "gather = torch.jit.trace(_gather, ({0: torch.FloatTensor([0.])}, torch.LongTensor([0])))\n",
    "\n",
    "from typing import Tuple, List\n",
    "\n",
    "# @torch.jit.script\n",
    "def stable_arg_sort_long(arr):\n",
    "    \"\"\"Stable sort of long tensors.\n",
    "\n",
    "    Note that Pytorch 1.5.0 does not have a stable sort implementation.\n",
    "    Here we simply add a delta value between 0 and 1 (exclusive) and\n",
    "    assuming we are using integers, call torch.argsort to get a stable\n",
    "    sort.\n",
    "    \"\"\"\n",
    "    if not (arr.dtype == torch.long or arr.dtype == torch.int):\n",
    "        raise ValueError(\"only torch.Long or torch.Int allowed\")\n",
    "    dim = -1\n",
    "    if not dim == -1:\n",
    "        raise ValueError(\"only last dimension sort is supported. Try reshaping tensor.\")\n",
    "    delta_shape = list(arr.shape)\n",
    "    delta_shape[dim] = 1\n",
    "    mn = 0.\n",
    "    mx = 0.9\n",
    "    delta = torch.linspace(mn, mx, arr.shape[dim])\n",
    "    delta = delta.repeat(delta_shape)\n",
    "    return torch.argsort(arr + delta, dim=dim)\n",
    "\n",
    "traced_arg_sort_long = torch.jit.trace(stable_arg_sort_long, (torch.randint(1, 10, (10,))))\n",
    "\n",
    "def torch_scatter_group(\n",
    "    x: torch.Tensor, idx: torch.Tensor\n",
    ") -> Tuple[torch.Tensor, List[torch.Tensor]]:\n",
    "    \"\"\"Group a tensor by indices. This is equivalent to successive applications\n",
    "    of `x[torch.where(x == index)]` for all provided sorted indices.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    .. code-block:: python\n",
    "\n",
    "        idx = torch.tensor([2, 2, 0, 1, 1, 1, 2])\n",
    "        x = torch.tensor([0, 1, 2, 3, 4, 5, 6])\n",
    "\n",
    "        uniq_sorted_idx, out = scatter_group(x, idx)\n",
    "\n",
    "        # node the idx is sorted\n",
    "        assert torch.all(torch.eq(out[0], torch.tensor([0, 1, 2])))\n",
    "\n",
    "        # where idx == 0\n",
    "        assert torch.all(torch.eq(out[1][0], torch.tensor([2])))\n",
    "\n",
    "        # where idx == 1\n",
    "        assert torch.all(torch.eq(out[1][1], torch.tensor([3, 4, 5])))\n",
    "\n",
    "        # where idx == 2\n",
    "        assert torch.all(torch.eq(out[1][2], torch.tensor([0, 1, 6])))\n",
    "\n",
    "    :param x: tensor to group\n",
    "    :param idx: indices\n",
    "    :return: tuple of unique, sorted indices and a list of tensors corresponding to the groups\n",
    "    \"\"\"\n",
    "    arg = traced_arg_sort(idx)\n",
    "    x = x[arg]\n",
    "    groups, b = torch.unique(idx, return_counts=True)\n",
    "    i_a = 0\n",
    "    arr_list = []\n",
    "    for i_b in b:\n",
    "        arr_list.append(x[i_a : i_a + i_b.item()])\n",
    "        i_a += i_b.item()\n",
    "    return groups, arr_list\n",
    "\n",
    "traced_torch_scatter_group = torch.jit.trace(torch_scatter_group, (torch.randn(10), torch.randint(0, 10, (10,))))\n",
    "\n",
    "values = torch.randn(10000)\n",
    "idx = torch.randint(0, 10, (values.shape[0],))\n",
    "\n",
    "\n",
    "%timeit -n100 torch_scatter_group(values, idx)\n",
    "%timeit -n100 traced_torch_scatter_group(values, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling\n",
      "tensor([5, 9, 3, 7, 2, 5, 4, 8, 6, 8])\n",
      "tensor([              1, 140634073316320,               2,               6,\n",
      "                      9,               1,               0,               8,\n",
      "         94206487370624,               8])\n",
      "calling\n",
      "tensor([9, 9, 6, 3, 4, 8, 4, 4, 9, 6, 7, 7, 3, 8, 5, 2, 9, 5, 6, 1, 6, 9, 2, 8,\n",
      "        7, 8, 1, 4, 8, 1, 1, 2, 7, 5, 8, 3, 9, 2, 7, 9, 5, 4, 6, 6, 8, 8, 4, 4,\n",
      "        6, 8, 5, 7, 3, 4, 6, 2, 8, 7, 3, 2, 6, 1, 2, 4, 2, 5, 7, 7, 2, 5, 1, 6,\n",
      "        8, 8, 3, 6, 6, 3, 5, 7, 9, 2, 8, 5, 8, 9, 5, 7, 4, 3, 4, 5, 3, 2, 3, 3,\n",
      "        2, 5, 6, 3])\n",
      "tensor([93, 93, 89, 80, 98, 87, 98, 98, 93, 89, 99, 99, 80, 87, 76, 84, 93, 76,\n",
      "        89, 97, 89, 93, 84, 87, 99, 87, 97, 98, 87, 97, 97, 84, 99, 76, 87, 80,\n",
      "        93, 84, 99, 93, 76, 98, 89, 89, 87, 87, 98, 98, 89, 87, 76, 99, 80, 98,\n",
      "        89, 84, 87, 99, 80, 84, 89, 97, 84, 98, 84, 76, 99, 99, 84, 76, 97, 89,\n",
      "        87, 87, 80, 89, 89, 80, 76, 99, 93, 84, 87, 76, 87, 93, 76, 99, 98, 80,\n",
      "        98, 76, 80, 84, 80, 80, 84, 76, 89, 80])\n",
      "457 µs ± 7.07 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "48.6 ms ± 286 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "33.6 ms ± 114 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "tensor([9, 9, 6, 3, 4, 8, 4, 4, 9, 6, 7, 7, 3, 8, 5, 2, 9, 5, 6, 1, 6, 9, 2, 8,\n",
      "        7, 8, 1, 4, 8, 1, 1, 2, 7, 5, 8, 3, 9, 2, 7, 9, 5, 4, 6, 6, 8, 8, 4, 4,\n",
      "        6, 8, 5, 7, 3, 4, 6, 2, 8, 7, 3, 2, 6, 1, 2, 4, 2, 5, 7, 7, 2, 5, 1, 6,\n",
      "        8, 8, 3, 6, 6, 3, 5, 7, 9, 2, 8, 5, 8, 9, 5, 7, 4, 3, 4, 5, 3, 2, 3, 3,\n",
      "        2, 5, 6, 3])\n",
      "tensor([8, 3, 5, 6, 9, 2, 7, 8, 2, 3, 7, 7, 9, 7, 3, 6, 8, 9, 8, 3, 2, 5, 9, 1,\n",
      "        6, 9, 4, 4, 7, 2, 3, 2, 1, 3, 3, 8, 2, 7, 9, 6, 1, 5, 4, 5, 6, 6, 1, 2,\n",
      "        4, 5, 8, 1, 4, 4, 6, 7, 1, 2, 5, 5, 4, 4, 1, 6, 9, 9, 2, 3, 9, 1, 5, 4,\n",
      "        1, 5, 1, 4, 5, 7, 1, 4, 3, 2, 1, 9, 2, 1, 8, 8, 1, 6, 7, 7, 4, 9, 7, 1,\n",
      "        4, 1, 4, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 4, 12, 17,  ..., 34, 67, 80])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ij = torch.randint(1, 10, (4, 100))\n",
    "values = torch.arange(ij.shape[1])\n",
    "\n",
    "m = scatter_coo(ij, values)\n",
    "\n",
    "k, v = traced_torch_scatter_group(m._values(), m._indices()[-1])\n",
    "data = dict(zip(k.tolist(), v))\n",
    "\n",
    "_gather(data, torch.LongTensor([0, 1, 2, 3]))\n",
    "\n",
    "def where_is_in(idx: torch.LongTensor, a: torch.LongTensor):\n",
    "    values = torch.arange(a.shape[-1])\n",
    "    m = scatter_coo(a, values)\n",
    "    k, v = torch_scatter_group(m._values(), m._indices()[-1])\n",
    "    data = dict(zip(k.tolist(), v))\n",
    "    return _gather(data, idx)\n",
    "\n",
    "def other_where_is_in(a: torch.Tensor, b: torch.Tensor):\n",
    "    result = torch.empty_like(a)\n",
    "    for i in range(a.shape[0]):\n",
    "        _a = a[i]\n",
    "        for j in range(b.shape[0]):\n",
    "            _b = b[j]\n",
    "            if _a == _b:\n",
    "                result[i] = j\n",
    "    return result\n",
    "\n",
    "a = torch.randint(1, 10, (10,))\n",
    "b = torch.randint(1, 10, (10,))\n",
    "\n",
    "traced_other_where_is_in = torch.jit.script(other_where_is_in) # (a, b))\n",
    "\n",
    "\n",
    "a = torch.randint(1, 10, (10,))\n",
    "b = torch.randint(1, 10, (10,))\n",
    "print('calling')\n",
    "print(a)\n",
    "c = traced_other_where_is_in(a, b)\n",
    "print(c)\n",
    "\n",
    "a = torch.randint(1, 10, (100,))\n",
    "b = torch.randint(1, 10, (100,))\n",
    "print('calling')\n",
    "print(a)\n",
    "c = traced_other_where_is_in(a, b)\n",
    "print(c)\n",
    "%timeit -n100 where_is_in(a, b)\n",
    "%timeit -n10 other_where_is_in(a, b)\n",
    "%timeit -n10 traced_other_where_is_in(a, b)\n",
    "print(a)\n",
    "print(b)\n",
    "where_is_in(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.randint(1, 20, (10,))\n",
    "# b = torch.randint(1, 20, (10,))\n",
    "\n",
    "# k, v = torch_scatter_group(a, b)\n",
    "\n",
    "# data = dict(zip(k.tolist(), v))\n",
    "\n",
    "# nodes = torch.tensor([1, 2, 3, 4])\n",
    "\n",
    "# %timeit -n100 _gather(data, nodes)\n",
    "# %timeit -n100 long_isin(a, b)\n",
    "a = torch.tensor([0, 1, 2, 3, 4])\n",
    "b = torch.tensor([\n",
    "    [0, 1, 2, 3],\n",
    "    [3, 3, 3, 4]\n",
    "])\n",
    "\n",
    "k, v = torch_scatter_group(a.repeat(2), b.flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "indices and values must have same nnz, but got nnz from indices: 100, nnz from values: 10000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-1e89bd76b903>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_coo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mij\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# from torch_sparse import SparseTensor?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/caldera/caldera/utils/sparse.py\u001b[0m in \u001b[0;36mscatter_coo\u001b[0;34m(indices, source, size, expand, dtype)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0msidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_coo_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msidx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflattened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/caldera/caldera/utils/sparse.py\u001b[0m in \u001b[0;36m_coo_tensor\u001b[0;34m(indices, source, size, dtype, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_coo_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: indices and values must have same nnz, but got nnz from indices: 100, nnz from values: 10000"
     ]
    }
   ],
   "source": [
    "import torch_sparse\n",
    "\n",
    "m = scatter_coo(ij, values)\n",
    "m\n",
    "# from torch_sparse import SparseTensor?\n",
    "\n",
    "# SparseTensor()\n",
    "# torch_sparse.index_select(m, 0, torch.LongTensor([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " [tensor([[ 0, 10, 23, 40, 53, 60, 69, 80, 85, 86, 91, 96,  1,  9, 11, 39, 43, 52,\n",
       "           66, 67, 76, 93, 95,  6, 14, 18, 26, 42, 49, 56, 57, 59, 61, 72, 73, 77,\n",
       "           78, 79, 89,  3,  7, 13, 19, 21, 45, 82,  2, 12, 16, 17, 34, 37, 44, 51,\n",
       "           54, 55, 81, 94, 99,  8, 22, 24, 29, 30, 35, 36, 46, 47, 48, 75, 83, 84,\n",
       "           97, 28, 31, 38, 68, 87, 90,  5, 20, 25, 27, 33, 41, 58, 62, 65, 74,  4,\n",
       "           15, 32, 50, 63, 64, 70, 71, 88, 92, 98],\n",
       "          [14, 16, 17, 24, 48, 90, 92,  1,  6, 11, 15, 30, 35, 37, 40, 55, 62, 69,\n",
       "           74, 81, 85, 89,  3,  8, 19, 25, 26, 28, 39, 43, 52, 73, 79, 82, 97, 10,\n",
       "           34, 38, 44, 45, 59, 61, 63, 68, 86, 93,  5, 12, 20, 23, 41, 47, 50, 60,\n",
       "           64, 78, 95, 99, 21, 27, 36, 42, 46, 71, 84, 87, 94,  0,  9, 13, 22, 29,\n",
       "           31, 32, 49, 54, 57, 67, 72, 75, 76, 80, 91, 96,  2,  4, 18, 33, 51, 56,\n",
       "           77, 88, 98,  7, 53, 58, 65, 66, 70, 83]]),\n",
       "  tensor([], size=(0, 100), dtype=torch.int64),\n",
       "  tensor([], size=(0, 100), dtype=torch.int64),\n",
       "  tensor([], size=(0, 100), dtype=torch.int64),\n",
       "  tensor([], size=(0, 100), dtype=torch.int64),\n",
       "  tensor([], size=(0, 100), dtype=torch.int64),\n",
       "  tensor([], size=(0, 100), dtype=torch.int64),\n",
       "  tensor([], size=(0, 100), dtype=torch.int64),\n",
       "  tensor([], size=(0, 100), dtype=torch.int64)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from caldera.utils import torch_scatter_group\n",
    "\n",
    "torch_scatter_group(m._values(), m._indices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Getting Started &#8212; caldera 0.1.0 documentation</title>
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/style.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script src="_static/copybutton.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="API Documentation" href="api.html" />
    <link rel="prev" title="Caldera" href="index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js "></script>

  </head><body>



  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          Caldera 0.1.0</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="#">Getting Started</a></li>
                <li><a href="examples/examples.html">Examples</a></li>
                <li><a href="api.html">API</a></li>
                <li><a href="http://www.github.com/jvrana/caldera">Github</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Caldera <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Getting Started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#installation">Installation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API Documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="generated/caldera.data.html">caldera.data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/caldera.data.html#data-caldera-data">Data (<code class="xref py py-mod docutils literal notranslate"><span class="pre">caldera.data</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="generated/caldera.blocks.html">caldera.blocks</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/caldera.blocks.html#blocks-caldera-blocks">Blocks (<code class="xref py py-mod docutils literal notranslate"><span class="pre">caldera.blocks</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="generated/caldera.models.html">caldera.models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/caldera.models.html#data-caldera-models">Data (<code class="xref py py-mod docutils literal notranslate"><span class="pre">caldera.models</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="generated/caldera.transforms.html">caldera.transforms</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/caldera.transforms.html#transforms-caldera-transform">Transforms (<code class="xref py py-mod docutils literal notranslate"><span class="pre">caldera.transform</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="generated/caldera.utils.html">caldera.utils</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/caldera.utils.html#utils-caldera-utils">Utils (<code class="xref py py-mod docutils literal notranslate"><span class="pre">caldera.utils</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="generated/caldera.exceptions.html">caldera.exceptions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/caldera.exceptions.html#exceptions-caldera-exceptions">Exceptions (<code class="xref py py-mod docutils literal notranslate"><span class="pre">caldera.exceptions</span></code>)</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="generated/caldera.defaults.html">caldera.defaults</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/caldera.defaults.html#defaults-caldera-defaults">Defaults (<code class="xref py py-mod docutils literal notranslate"><span class="pre">caldera.defaults</span></code>)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="examples/examples.html">Examples</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Getting Started</a><ul>
<li><a class="reference internal" href="#installation">Installation</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="getting-started">
<h1>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h1>
<div class="section" id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">latent_sizes</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">depths</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">pass_global_to_edge</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">pass_global_to_node</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">edge_to_node_aggregators</span><span class="o">=</span><span class="nb">tuple</span><span class="p">([</span><span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">]),</span>
        <span class="n">edge_to_global_aggregators</span><span class="o">=</span><span class="nb">tuple</span><span class="p">([</span><span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">]),</span>
        <span class="n">node_to_global_aggregators</span><span class="o">=</span><span class="nb">tuple</span><span class="p">([</span><span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">,</span> <span class="s2">&quot;mean&quot;</span><span class="p">,</span> <span class="s2">&quot;min&quot;</span><span class="p">]),</span>
        <span class="n">aggregator_activation</span><span class="o">=</span><span class="n">defaults</span><span class="o">.</span><span class="n">activation</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;latent_size&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;node&quot;</span><span class="p">:</span> <span class="n">latent_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="s2">&quot;edge&quot;</span><span class="p">:</span> <span class="n">latent_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="s2">&quot;global&quot;</span><span class="p">:</span> <span class="n">latent_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                <span class="s2">&quot;core_node_block_depth&quot;</span><span class="p">:</span> <span class="n">depths</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="s2">&quot;core_edge_block_depth&quot;</span><span class="p">:</span> <span class="n">depths</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="s2">&quot;core_global_block_depth&quot;</span><span class="p">:</span> <span class="n">depths</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
            <span class="p">},</span>
            <span class="s2">&quot;node_block_aggregator&quot;</span><span class="p">:</span> <span class="n">edge_to_node_aggregators</span><span class="p">,</span>
            <span class="s2">&quot;global_block_to_node_aggregator&quot;</span><span class="p">:</span> <span class="n">node_to_global_aggregators</span><span class="p">,</span>
            <span class="s2">&quot;global_block_to_edge_aggregator&quot;</span><span class="p">:</span> <span class="n">edge_to_global_aggregators</span><span class="p">,</span>
            <span class="s2">&quot;aggregator_activation&quot;</span><span class="p">:</span> <span class="n">aggregator_activation</span><span class="p">,</span>
            <span class="s2">&quot;pass_global_to_edge&quot;</span><span class="p">:</span> <span class="n">pass_global_to_edge</span><span class="p">,</span>
            <span class="s2">&quot;pass_global_to_node&quot;</span><span class="p">:</span> <span class="n">pass_global_to_node</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">GraphEncoder</span><span class="p">(</span>
            <span class="n">EdgeBlock</span><span class="p">(</span><span class="n">Flex</span><span class="p">(</span><span class="n">MLP</span><span class="p">)(</span><span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span> <span class="n">latent_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)),</span>
            <span class="n">NodeBlock</span><span class="p">(</span><span class="n">Flex</span><span class="p">(</span><span class="n">MLP</span><span class="p">)(</span><span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span> <span class="n">latent_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)),</span>
            <span class="n">GlobalBlock</span><span class="p">(</span><span class="n">Flex</span><span class="p">(</span><span class="n">MLP</span><span class="p">)(</span><span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span> <span class="n">latent_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)),</span>
        <span class="p">)</span>

        <span class="n">edge_layers</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;latent_size&quot;</span><span class="p">][</span><span class="s2">&quot;edge&quot;</span><span class="p">]]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;latent_size&quot;</span><span class="p">][</span>
            <span class="s2">&quot;core_edge_block_depth&quot;</span>
        <span class="p">]</span>
        <span class="n">node_layers</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;latent_size&quot;</span><span class="p">][</span><span class="s2">&quot;node&quot;</span><span class="p">]]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;latent_size&quot;</span><span class="p">][</span>
            <span class="s2">&quot;core_node_block_depth&quot;</span>
        <span class="p">]</span>
        <span class="n">global_layers</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;latent_size&quot;</span><span class="p">][</span><span class="s2">&quot;global&quot;</span><span class="p">]]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span>
            <span class="s2">&quot;latent_size&quot;</span>
        <span class="p">][</span><span class="s2">&quot;core_global_block_depth&quot;</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">core</span> <span class="o">=</span> <span class="n">GraphCore</span><span class="p">(</span>
            <span class="n">AggregatingEdgeBlock</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">Flex</span><span class="p">(</span><span class="n">MLP</span><span class="p">)(</span><span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span> <span class="o">*</span><span class="n">edge_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> <span class="n">layer_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="c1"># Flex(torch.nn.Linear)(Flex.d(), edge_layers[-1])</span>
                <span class="p">)</span>
            <span class="p">),</span>
            <span class="n">AggregatingNodeBlock</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">Flex</span><span class="p">(</span><span class="n">MLP</span><span class="p">)(</span><span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span> <span class="o">*</span><span class="n">node_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> <span class="n">layer_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="c1"># Flex(torch.nn.Linear)(Flex.d(), node_layers[-1])</span>
                <span class="p">),</span>
                <span class="n">Flex</span><span class="p">(</span><span class="n">MultiAggregator</span><span class="p">)(</span>
                    <span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;node_block_aggregator&quot;</span><span class="p">],</span>
                    <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;aggregator_activation&quot;</span><span class="p">],</span>
                <span class="p">),</span>
            <span class="p">),</span>
            <span class="n">AggregatingGlobalBlock</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">Flex</span><span class="p">(</span><span class="n">MLP</span><span class="p">)(</span>
                        <span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span> <span class="o">*</span><span class="n">global_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> <span class="n">layer_norm</span><span class="o">=</span><span class="kc">True</span>
                    <span class="p">),</span>
                    <span class="c1"># Flex(torch.nn.Linear)(Flex.d(), global_layers[-1])</span>
                <span class="p">),</span>
                <span class="n">edge_aggregator</span><span class="o">=</span><span class="n">Flex</span><span class="p">(</span><span class="n">MultiAggregator</span><span class="p">)(</span>
                    <span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;global_block_to_edge_aggregator&quot;</span><span class="p">],</span>
                    <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;aggregator_activation&quot;</span><span class="p">],</span>
                <span class="p">),</span>
                <span class="n">node_aggregator</span><span class="o">=</span><span class="n">Flex</span><span class="p">(</span><span class="n">MultiAggregator</span><span class="p">)(</span>
                    <span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;global_block_to_node_aggregator&quot;</span><span class="p">],</span>
                    <span class="n">activation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;aggregator_activation&quot;</span><span class="p">],</span>
                <span class="p">),</span>
            <span class="p">),</span>
            <span class="n">pass_global_to_edge</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;pass_global_to_edge&quot;</span><span class="p">],</span>
            <span class="n">pass_global_to_node</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;pass_global_to_node&quot;</span><span class="p">],</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">GraphEncoder</span><span class="p">(</span>
            <span class="n">EdgeBlock</span><span class="p">(</span>
                <span class="n">Flex</span><span class="p">(</span><span class="n">MLP</span><span class="p">)(</span><span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span> <span class="n">latent_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">latent_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
            <span class="p">),</span>
            <span class="n">NodeBlock</span><span class="p">(</span>
                <span class="n">Flex</span><span class="p">(</span><span class="n">MLP</span><span class="p">)(</span><span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span> <span class="n">latent_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">latent_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
            <span class="p">),</span>
            <span class="n">GlobalBlock</span><span class="p">(</span><span class="n">Flex</span><span class="p">(</span><span class="n">MLP</span><span class="p">)(</span><span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span> <span class="n">latent_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">])),</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">output_transform</span> <span class="o">=</span> <span class="n">GraphEncoder</span><span class="p">(</span>
            <span class="n">EdgeBlock</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">Flex</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)(</span><span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
                <span class="p">)</span>
            <span class="p">),</span>
            <span class="n">NodeBlock</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
                    <span class="n">Flex</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)(</span><span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span> <span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
                <span class="p">)</span>
            <span class="p">),</span>
            <span class="n">GlobalBlock</span><span class="p">(</span><span class="n">Flex</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)(</span><span class="n">Flex</span><span class="o">.</span><span class="n">d</span><span class="p">(),</span> <span class="mi">1</span><span class="p">)),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">save_all</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="c1"># encoded</span>
        <span class="n">e</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">GraphBatch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edges</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">node_idx</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_idx</span><span class="p">)</span>

        <span class="c1"># graph topography data</span>
        <span class="n">edges</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">edges</span>
        <span class="n">node_idx</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">node_idx</span>
        <span class="n">edge_idx</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">edge_idx</span>
        <span class="n">latent0</span> <span class="o">=</span> <span class="n">data</span>

        <span class="n">meta</span> <span class="o">=</span> <span class="p">(</span><span class="n">edges</span><span class="p">,</span> <span class="n">node_idx</span><span class="p">,</span> <span class="n">edge_idx</span><span class="p">)</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
            <span class="c1"># core processing step</span>
            <span class="n">e</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">latent0</span><span class="o">.</span><span class="n">e</span><span class="p">,</span> <span class="n">e</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">latent0</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">g</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">latent0</span><span class="o">.</span><span class="n">g</span><span class="p">,</span> <span class="n">g</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">GraphBatch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="o">*</span><span class="n">meta</span><span class="p">)</span>
            <span class="n">e</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">core</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

            <span class="c1"># decode</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">GraphBatch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">e</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="o">*</span><span class="n">meta</span><span class="p">)</span>

            <span class="n">_e</span><span class="p">,</span> <span class="n">_x</span><span class="p">,</span> <span class="n">_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
            <span class="n">decoded</span> <span class="o">=</span> <span class="n">GraphBatch</span><span class="p">(</span><span class="n">_x</span><span class="p">,</span> <span class="n">_e</span><span class="p">,</span> <span class="n">_g</span><span class="p">,</span> <span class="o">*</span><span class="n">meta</span><span class="p">)</span>

            <span class="c1"># transform</span>
            <span class="n">_e</span><span class="p">,</span> <span class="n">_x</span><span class="p">,</span> <span class="n">_g</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_transform</span><span class="p">(</span><span class="n">decoded</span><span class="p">)</span>
            <span class="n">gt</span> <span class="o">=</span> <span class="n">GraphBatch</span><span class="p">(</span><span class="n">_x</span><span class="p">,</span> <span class="n">_e</span><span class="p">,</span> <span class="n">_g</span><span class="p">,</span> <span class="n">edges</span><span class="p">,</span> <span class="n">node_idx</span><span class="p">,</span> <span class="n">edge_idx</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">save_all</span><span class="p">:</span>
                <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gt</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">gt</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">outputs</span>
</pre></div>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="_sources/getting_started.rst.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2020, Justin Vrana &lt;justin.vrana@gmail.com&gt;.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.2.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>